{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n\n# Load pre-trained ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False)\n\n# Load labels\nlabels_df = pd.read_csv('/kaggle/input/amazonsatelliteimages/train_v2.csv/train_v2.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:38:16.297969Z","iopub.execute_input":"2023-05-10T02:38:16.298445Z","iopub.status.idle":"2023-05-10T02:38:18.347345Z","shell.execute_reply.started":"2023-05-10T02:38:16.298407Z","shell.execute_reply":"2023-05-10T02:38:18.346351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create binary labels for 'habitation' and 'slash_burn'\nlabels_df['deforestation'] = labels_df['tags'].apply(lambda x: 1 if 'habitation' in x else 0)\nlabels_df['pollution'] = labels_df['tags'].apply(lambda x: 1 if 'slash_burn' in x else 0)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:38:24.820815Z","iopub.execute_input":"2023-05-10T02:38:24.821257Z","iopub.status.idle":"2023-05-10T02:38:24.920234Z","shell.execute_reply.started":"2023-05-10T02:38:24.821222Z","shell.execute_reply":"2023-05-10T02:38:24.919378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training and validation sets\ntrain_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:38:37.642172Z","iopub.execute_input":"2023-05-10T02:38:37.642640Z","iopub.status.idle":"2023-05-10T02:38:37.664619Z","shell.execute_reply.started":"2023-05-10T02:38:37.642605Z","shell.execute_reply":"2023-05-10T02:38:37.663708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add file extensions to image filenames\ntrain_df['image_name'] = train_df['image_name'].apply(lambda x: f\"{x}.jpg\")\nval_df['image_name'] = val_df['image_name'].apply(lambda x: f\"{x}.jpg\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:40:16.032167Z","iopub.execute_input":"2023-05-10T02:40:16.032800Z","iopub.status.idle":"2023-05-10T02:40:16.057023Z","shell.execute_reply.started":"2023-05-10T02:40:16.032763Z","shell.execute_reply":"2023-05-10T02:40:16.055950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Function to create generator for the dataset\ndef create_dataset_generator(df, data_dir, batch_size=32, target_size=(224, 224)):\n    datagen = ImageDataGenerator(rescale=1./255)\n    generator = datagen.flow_from_dataframe(\n        df, directory=data_dir, x_col='image_name', y_col=['deforestation', 'pollution'],\n        target_size=target_size, batch_size=batch_size, class_mode='raw')\n    return generator\n\n# Set the path to dataset directory\ndata_dir = '/kaggle/input/amazonsatelliteimages/train-jpg/train-jpg'\n\n# Create dataset generators for training and validation sets\ntrain_generator = create_dataset_generator(train_df, data_dir)\nval_generator = create_dataset_generator(val_df, data_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:40:27.445648Z","iopub.execute_input":"2023-05-10T02:40:27.446015Z","iopub.status.idle":"2023-05-10T02:43:11.363629Z","shell.execute_reply.started":"2023-05-10T02:40:27.445987Z","shell.execute_reply":"2023-05-10T02:43:11.362259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add custom layers for specific task\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(2, activation='sigmoid')(x)\n\n# Create final model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:44:38.305148Z","iopub.execute_input":"2023-05-10T02:44:38.305527Z","iopub.status.idle":"2023-05-10T02:44:38.339872Z","shell.execute_reply.started":"2023-05-10T02:44:38.305496Z","shell.execute_reply":"2023-05-10T02:44:38.339025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the base_model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:44:43.736906Z","iopub.execute_input":"2023-05-10T02:44:43.739483Z","iopub.status.idle":"2023-05-10T02:44:43.762991Z","shell.execute_reply.started":"2023-05-10T02:44:43.739447Z","shell.execute_reply":"2023-05-10T02:44:43.762105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_generator, epochs=10, validation_data=val_generator)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T02:46:09.977969Z","iopub.execute_input":"2023-05-10T02:46:09.978317Z","iopub.status.idle":"2023-05-10T03:15:18.864814Z","shell.execute_reply.started":"2023-05-10T02:46:09.978289Z","shell.execute_reply":"2023-05-10T03:15:18.863873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\n\ndef predict_deforestation_pollution(model, img_path, img_size=(224, 224)):\n    # Load and preprocess image\n    img = image.load_img(img_path, target_size=img_size)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = x / 255.0\n\n    # Make a prediction using model\n    preds = model.predict(x)\n\n    return preds\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T03:23:06.501765Z","iopub.execute_input":"2023-05-10T03:23:06.502140Z","iopub.status.idle":"2023-05-10T03:23:06.508654Z","shell.execute_reply.started":"2023-05-10T03:23:06.502110Z","shell.execute_reply":"2023-05-10T03:23:06.507689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport matplotlib.pyplot as plt\n\ndef display_image_with_predictions(img_path, deforestation_prob, pollution_prob):\n    img = image.load_img(img_path)\n\n    plt.figure()\n    plt.imshow(img)\n    plt.title(f\"Deforestation Probability: {deforestation_prob:.4f}\\nPollution Probability: {pollution_prob:.4f}\")\n    plt.axis(\"off\")\n    plt.show()\n\n# Set path to the test dataset directory\ntest_data_dir = '/kaggle/input/amazonsatelliteimages/test-jpg/test-jpg'\n\n# Choose a few random images from test dataset\ntest_images = random.sample(os.listdir(test_data_dir), 5)\n\n# Evaluate model's performance on selected test images\nfor img_name in test_images:\n    img_path = os.path.join(test_data_dir, img_name)\n    preds = predict_deforestation_pollution(model, img_path)\n\n    deforestation_prob = preds[0][0]\n    pollution_prob = preds[0][1]\n\n    display_image_with_predictions(img_path, deforestation_prob, pollution_prob)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T03:25:39.254780Z","iopub.execute_input":"2023-05-10T03:25:39.255406Z","iopub.status.idle":"2023-05-10T03:25:41.559882Z","shell.execute_reply.started":"2023-05-10T03:25:39.255358Z","shell.execute_reply":"2023-05-10T03:25:41.558939Z"},"trusted":true},"execution_count":null,"outputs":[]}]}